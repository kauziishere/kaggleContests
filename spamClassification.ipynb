{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Classification\n",
    "### Used 2 Models Baseline Dense and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, Activation, Embedding, LSTM\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../spam.csv\", encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v1' 'v2' 'Unnamed: 2' 'Unnamed: 3' 'Unnamed: 4']\n"
     ]
    }
   ],
   "source": [
    "print(data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_attribute_sub = dict(zip(['spam', 'ham'], [1, 0]))\n",
    "for i in range(0, len(data)):\n",
    "    data['v1'][i] = y_attribute_sub[data['v1'][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  v1                                                 v2 Unnamed: 2 Unnamed: 3  \\\n",
      "0  0  Go until jurong point, crazy.. Available only ...        NaN        NaN   \n",
      "1  0                      Ok lar... Joking wif u oni...        NaN        NaN   \n",
      "2  1  Free entry in 2 a wkly comp to win FA Cup fina...        NaN        NaN   \n",
      "3  0  U dun say so early hor... U c already then say...        NaN        NaN   \n",
      "4  0  Nah I don't think he goes to usf, he lives aro...        NaN        NaN   \n",
      "\n",
      "  Unnamed: 4  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  v1                                                 v2\n",
      "0  0  Go until jurong point, crazy.. Available only ...\n",
      "1  0                      Ok lar... Joking wif u oni...\n",
      "2  1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3  0  U dun say so early hor... U c already then say...\n",
      "4  0  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Method:\n",
    "\n",
    "Using Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10864\n"
     ]
    }
   ],
   "source": [
    "\"\"\"corpus = list()\n",
    "for i in range(0, len(data)):\n",
    "    corpus.extend(re.sub(r'[^\\w]', ' ', data['v2'][i]).strip().split())\n",
    "corpus = list(set(corpus))\n",
    "print(len(corpus))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"encoding = dict(zip(corpus, [i+1 for i in range(0, len(corpus))]))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  v1                                                 v2\n",
      "0  0  [385, 5646, 5394, 759, 6982, 5545, 2620, 946, ...\n",
      "1  0                 [2941, 638, 726, 5094, 3673, 3798]\n",
      "2  1  [4376, 6104, 946, 6165, 6497, 2132, 5056, 4765...\n",
      "3  0  [239, 2479, 6063, 566, 1061, 6776, 239, 3926, ...\n",
      "4  0  [1862, 1930, 5116, 9961, 4940, 3371, 9909, 476... 190\n"
     ]
    }
   ],
   "source": [
    "\"\"\"max_length = 0\n",
    "for i in range(0, len(data)):\n",
    "    vector = re.sub(r'[^\\w]', ' ', data['v2'][i]).strip().split()\n",
    "    for j in range(0, len(vector)):\n",
    "        vector[j] = encoding[vector[j]]\n",
    "    data['v2'][i] = vector\n",
    "    if(max_length < len(vector)):\n",
    "        max_length = len(vector)\n",
    "print(data.head(), max_length)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  v1                                                 v2\n",
      "0  0  [385, 5646, 5394, 759, 6982, 5545, 2620, 946, ...\n",
      "1  0                 [2941, 638, 726, 5094, 3673, 3798]\n",
      "2  1  [4376, 6104, 946, 6165, 6497, 2132, 5056, 4765...\n",
      "3  0  [239, 2479, 6063, 566, 1061, 6776, 239, 3926, ...\n",
      "4  0  [1862, 1930, 5116, 9961, 4940, 3371, 9909, 476...\n",
      "  v1                                                 v2\n",
      "0  0  [385, 5646, 5394, 759, 6982, 5545, 2620, 946, ...\n",
      "1  0  [2941, 638, 726, 5094, 3673, 3798, 0, 0, 0, 0,...\n",
      "2  1  [4376, 6104, 946, 6165, 6497, 2132, 5056, 4765...\n",
      "3  0  [239, 2479, 6063, 566, 1061, 6776, 239, 3926, ...\n",
      "4  0  [1862, 1930, 5116, 9961, 4940, 3371, 9909, 476...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"print(data.head())\n",
    "X = np.zeros((len(data['v2']), max_length))\n",
    "for i in range(1, len(data)):\n",
    "    data['v2'][i].extend([0 for j in range(0, max_length-len(data['v2'][i]))])\n",
    "    X[i,:] = data['v2'][i]\n",
    "print(data.head())\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Tokenizer from keras with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.v2\n",
    "y = data.v1\n",
    "le_obj = LabelEncoder()\n",
    "y = le_obj.fit_transform(y)\n",
    "y = y.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 150\n",
    "max_words = 1000\n",
    "token = Tokenizer(num_words = max_words)\n",
    "token.fit_on_texts(X_train)\n",
    "sequences = token.texts_to_sequences(X_train)\n",
    "X_train = sequence.pad_sequences(sequences, maxlen = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_dense():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape=(max_length, ), activation ='relu', name='dense_7'))\n",
    "    model.add(Dense(30, activation='relu', name='dense_2'))\n",
    "    model.add(Dense(1, activation='sigmoid', name='dense_3'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(corpus), 16, input_length = max_length, name = 'embedding'))\n",
    "    model.add(LSTM(64, return_sequences = True, name = 'lstm_1'))\n",
    "    model.add(LSTM(32, return_sequences = False, name = 'lstm_2'))\n",
    "    model.add(Dense(1, activation='sigmoid', name = 'dense_1'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Model Testing with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 150, 16)           173824    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 150, 64)           20736     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 207,009\n",
      "Trainable params: 207,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = lstm()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input: (4457, 150) and 150 and shape of output: [0]\n",
      "Epoch 1/10\n",
      "4457/4457 [==============================] - 16s 4ms/step - loss: 0.4747 - acc: 0.8609\n",
      "Epoch 2/10\n",
      "4457/4457 [==============================] - 16s 4ms/step - loss: 0.2142 - acc: 0.9172\n",
      "Epoch 3/10\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0869 - acc: 0.9818\n",
      "Epoch 4/10\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0561 - acc: 0.9865\n",
      "Epoch 5/10\n",
      "4457/4457 [==============================] - 20s 4ms/step - loss: 0.0427 - acc: 0.9904\n",
      "Epoch 6/10\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0307 - acc: 0.9935\n",
      "Epoch 7/10\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0253 - acc: 0.9939\n",
      "Epoch 8/10\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0178 - acc: 0.9960\n",
      "Epoch 9/10\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0148 - acc: 0.9966\n",
      "Epoch 10/10\n",
      "4457/4457 [==============================] - 20s 4ms/step - loss: 0.0109 - acc: 0.9973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f14766f56a0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of input: {} and {} and shape of output: {}\".format(X_train.shape, len(X_train[0]), y_train[0]))\n",
    "model.fit(X_train, y_train, epochs=10, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115/1115 [==============================] - 4s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10696884384462317, 0.9739910313901345]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = token.texts_to_sequences(X_test)\n",
    "X_test = sequence.pad_sequences(sequences, maxlen = max_length)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with Dense Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                3030      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 18,161\n",
      "Trainable params: 18,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = baseline_dense()\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
