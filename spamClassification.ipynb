{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Classification\n",
    "### Used 2 Models Baseline Dense and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, Activation, Embedding, LSTM\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../spam.csv\", encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v1' 'v2' 'Unnamed: 2' 'Unnamed: 3' 'Unnamed: 4']\n"
     ]
    }
   ],
   "source": [
    "print(data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_attribute_sub = dict(zip(['spam', 'ham'], [1, 0]))\n",
    "for i in range(0, len(data)):\n",
    "    data['v1'][i] = y_attribute_sub[data['v1'][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  v1                                                 v2 Unnamed: 2 Unnamed: 3  \\\n",
      "0  0  Go until jurong point, crazy.. Available only ...        NaN        NaN   \n",
      "1  0                      Ok lar... Joking wif u oni...        NaN        NaN   \n",
      "2  1  Free entry in 2 a wkly comp to win FA Cup fina...        NaN        NaN   \n",
      "3  0  U dun say so early hor... U c already then say...        NaN        NaN   \n",
      "4  0  Nah I don't think he goes to usf, he lives aro...        NaN        NaN   \n",
      "\n",
      "  Unnamed: 4  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  v1                                                 v2\n",
      "0  0  Go until jurong point, crazy.. Available only ...\n",
      "1  0                      Ok lar... Joking wif u oni...\n",
      "2  1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3  0  U dun say so early hor... U c already then say...\n",
      "4  0  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Method:\n",
    "\n",
    "Using Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"corpus = list()\n",
    "for i in range(0, len(data)):\n",
    "    corpus.extend(re.sub(r'[^\\w]', ' ', data['v2'][i]).strip().split())\n",
    "corpus = list(set(corpus))\n",
    "print(len(corpus))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"encoding = dict(zip(corpus, [i+1 for i in range(0, len(corpus))]))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"max_length = 0\n",
    "for i in range(0, len(data)):\n",
    "    vector = re.sub(r'[^\\w]', ' ', data['v2'][i]).strip().split()\n",
    "    for j in range(0, len(vector)):\n",
    "        vector[j] = encoding[vector[j]]\n",
    "    data['v2'][i] = vector\n",
    "    if(max_length < len(vector)):\n",
    "        max_length = len(vector)\n",
    "print(data.head(), max_length)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"print(data.head())\n",
    "X = np.zeros((len(data['v2']), max_length))\n",
    "for i in range(1, len(data)):\n",
    "    data['v2'][i].extend([0 for j in range(0, max_length-len(data['v2'][i]))])\n",
    "    X[i,:] = data['v2'][i]\n",
    "print(data.head())\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Tokenizer from keras with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.v2\n",
    "y = data.v1\n",
    "le_obj = LabelEncoder()\n",
    "y = le_obj.fit_transform(y)\n",
    "y = y.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 150\n",
    "max_words = 1000\n",
    "token = Tokenizer(num_words = max_words)\n",
    "token.fit_on_texts(X_train)\n",
    "sequences = token.texts_to_sequences(X_train)\n",
    "X_train = sequence.pad_sequences(sequences, maxlen = max_length)\n",
    "sequences = token.texts_to_sequences(X_test)\n",
    "X_test = sequence.pad_sequences(sequences, maxlen = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_dense():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape=(max_length, ), activation ='relu', name='dense_7'))\n",
    "    model.add(Dense(30, activation='relu', name='dense_2'))\n",
    "    model.add(Dense(1, activation='sigmoid', name='dense_3'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, 16, input_length = max_length, name = 'embedding'))\n",
    "    model.add(LSTM(64, return_sequences = True, name = 'lstm_1'))\n",
    "    model.add(LSTM(32, return_sequences = False, name = 'lstm_2'))\n",
    "    model.add(Dense(1, activation='sigmoid', name = 'dense_1'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Model Testing with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 150, 16)           16000     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 150, 64)           20736     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 49,185\n",
      "Trainable params: 49,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = lstm()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input: (4457, 150) and 150 and shape of output: [0]\n",
      "Epoch 1/10\n",
      "4457/4457 [==============================] - 16s 4ms/step - loss: 0.4544 - acc: 0.8600\n",
      "Epoch 2/10\n",
      "4457/4457 [==============================] - 15s 3ms/step - loss: 0.1760 - acc: 0.9363\n",
      "Epoch 3/10\n",
      "4457/4457 [==============================] - 14s 3ms/step - loss: 0.0756 - acc: 0.9809\n",
      "Epoch 4/10\n",
      "4457/4457 [==============================] - 14s 3ms/step - loss: 0.0486 - acc: 0.9881\n",
      "Epoch 5/10\n",
      "4457/4457 [==============================] - 14s 3ms/step - loss: 0.0361 - acc: 0.9917\n",
      "Epoch 6/10\n",
      "4457/4457 [==============================] - 13s 3ms/step - loss: 0.0274 - acc: 0.9933\n",
      "Epoch 7/10\n",
      "4457/4457 [==============================] - 14s 3ms/step - loss: 0.0203 - acc: 0.9960\n",
      "Epoch 8/10\n",
      "4457/4457 [==============================] - 13s 3ms/step - loss: 0.0161 - acc: 0.9971\n",
      "Epoch 9/10\n",
      "4457/4457 [==============================] - 14s 3ms/step - loss: 0.0138 - acc: 0.9969\n",
      "Epoch 10/10\n",
      "4457/4457 [==============================] - 15s 3ms/step - loss: 0.0111 - acc: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1ea4461160>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of input: {} and {} and shape of output: {}\".format(X_train.shape, len(X_train[0]), y_train[0]))\n",
    "model.fit(X_train, y_train, epochs=10, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115/1115 [==============================] - 3s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11307094661527284, 0.9766816143497757]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with Dense Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                3030      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 18,161\n",
      "Trainable params: 18,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model = baseline_dense()\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4457/4457 [==============================] - 1s 138us/step - loss: 2.9594 - acc: 0.8010\n",
      "Epoch 2/10\n",
      "4457/4457 [==============================] - 0s 65us/step - loss: 2.1618 - acc: 0.8661\n",
      "Epoch 3/10\n",
      "4457/4457 [==============================] - 0s 59us/step - loss: 2.1617 - acc: 0.8661\n",
      "Epoch 4/10\n",
      "4457/4457 [==============================] - 0s 60us/step - loss: 2.1616 - acc: 0.8661\n",
      "Epoch 5/10\n",
      "4457/4457 [==============================] - 0s 69us/step - loss: 2.1615 - acc: 0.8661\n",
      "Epoch 6/10\n",
      "4457/4457 [==============================] - 0s 66us/step - loss: 2.1614 - acc: 0.8661\n",
      "Epoch 7/10\n",
      "4457/4457 [==============================] - 0s 58us/step - loss: 2.1613 - acc: 0.8661\n",
      "Epoch 8/10\n",
      "4457/4457 [==============================] - 0s 59us/step - loss: 2.1612 - acc: 0.8661\n",
      "Epoch 9/10\n",
      "4457/4457 [==============================] - 0s 67us/step - loss: 2.1611 - acc: 0.8661\n",
      "Epoch 10/10\n",
      "4457/4457 [==============================] - 0s 61us/step - loss: 2.1610 - acc: 0.8661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1ea83b01d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115/1115 [==============================] - 0s 100us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.146443904354968, 0.8654708518041089]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
